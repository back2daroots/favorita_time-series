# ğŸª Favorita Store Sales Forecasting

**Goal:**  
Build a time-series forecasting model to predict daily unit sales for each product family in each store, using historical sales, promotions, and calendar data.

## ğŸ“Š Dataset

| Property | Description |
|-----------|--------------|
| **Source** | [Kaggle â€” Store Sales Time Series Forecasting](https://www.kaggle.com/competitions/store-sales-time-series-forecasting) |
| **Size** | ~3.0M records across 54 stores and 33 product families |
| **Target Variable** | `sales` â€” daily unit sales for each (store, family) |

**Author:** back2daroots  
**Environment:** Python 3.11 (Conda, pip-tools), Linux/Mac  
**Core Libraries:** `pandas`, `numpy`, `scikit-learn`, `xgboost`, `optuna`, `yaml`, `matplotlib`, `seaborn`

---
## ğŸ“‚ Project Structure
```
store_sales/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml              # Feature, model, and path settings
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # Original CSVs (train, test, oil, holidays, transactions)
â”‚   â””â”€â”€ processed/               # Processed and feature-enriched data
â”œâ”€â”€ models/                      # Trained model artifacts (.joblib)
â”œâ”€â”€ results/                     # Evaluation outputs and error diagnostics
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data.py                  # Data loading and preparation
â”‚   â”œâ”€â”€ features.py              # Feature generation and FE logic
â”‚   â”œâ”€â”€ models.py                # Model definitions and wrappers
â”‚   â”œâ”€â”€ metrics.py               # RMSE, MAE, sMAPE, CV utils
â”‚   â”œâ”€â”€ logging_utils.py         # Experiment logging
â”‚   â””â”€â”€ utils.py                 # Helpers, validation, config parsing
â”‚
â”œâ”€â”€ cv_run.py                    # Cross-validation runner
â”œâ”€â”€ train.py                     # Train final model on full data
â”œâ”€â”€ analyze_errors.py            # Post-holdout error analysis
â”œâ”€â”€ experiments_log.csv          # Experiment registry
â”œâ”€â”€ environment.yml              # Environment specification
â””â”€â”€ .gitignore
```
---

## âš™ï¸ Modeling Pipeline

### 1ï¸âƒ£ Feature Engineering
The pipeline builds features per `(store_nbr, family)` group:
- **Lags:** 1, 7, 14, 28, 56, 84 days  
- **Rolling statistics:** mean & std over 7, 28, 56 days  
- **Promo features:** current & lagged `onpromotion`, rolling sums & means  
- **Calendar features:** day-of-week, month, year, is_weekend, month start/end  
- **Holidays:** `is_holiday`, `is_preholiday_1`, `is_postholiday_1`  
- **Interactions:** `rmean_sales_7 Ã— onpromotion`, `is_friday Ã— month_end`

All features are computed **causally** (using `shift(1)`), ensuring no data leakage.

---

## ğŸ§  Model Training

Models are defined in `src/models.py` and configured in `configs/config.yaml`.

Models experimented with:
- `XGBoostRegressor` (baseline)
- `LightGBMRegressor` (next)
- `CatBoostRegressor` (next)

Hyperparameter tuning was performed using **Optuna** with a 5-fold **time-series CV** split.

**Best model:** XGBoost  
**Best sMAPE:** `51.26`

---

## ğŸ“ˆ Final Model Performance

---

## ğŸ§ª Error Analysis (Holdout)

### ğŸ·ï¸ Top-5 Product Families (by MAE)
| Family     | MAE ($) |
|-------------|---------|
| BEVERAGES   | 104.21  |
| GROCERY I   | 100.18  |
| CLEANING    |  74.97  |
| PRODUCE     |  70.75  |
| DAIRY       |  36.72  |

### ğŸ¬ Top-4 Stores (by MAE)
| Store | MAE ($) |
|--------|----------|
| 44     |  50.41  |
| 47     |  45.55  |
| 45     |  40.71  |
| 46     |  37.70  |

### ğŸ“… Error by Day of Week
| DOW | MAE ($) |
|------|----------|
| 6 (Sunday)   | 24.63 |
| 5 (Saturday) | 24.44 |
| 4 (Friday)   | 20.86 |
| 0 (Monday)   | 20.82 |
| 3 (Thursday) | 17.94 |
| 1 (Tuesday)  | 17.93 |
| 2 (Wednesday)| 17.78 |

ğŸ§­ **Insight:**  
Errors peak for **promo-heavy product families** (Beverages, Grocery I)  
and **weekend demand**, especially in stores 44â€“47.

---

## ğŸ§© Next Steps

- Add **store- and category-level trend features**  
- Model **promotion durations** and multi-week promo effects  
- Introduce **seasonal Fourier features** (month, quarter)  
- Explore **model blending** (CatBoost + XGB)  
- Add **SHAP-based feature importance** for interpretability  

---
## ğŸ Final Results

| Model      | RMSE | MAE | sMAPE | Comment |
|-------------|------|-----|--------|----------|
| XGB         | 56.9 | 20.6 | 51.3 | Tuned baseline |
| LGBM        | 56.8 | 18.6 | 52.3 | Better alignment CV vs holdout |
| CatBoost    | 73.1 | 26.2 | 61.4 | Stable but lower |
| Blend (0.35 LGBM / 0.65 XGB) | â€” | â€” | **50.9** | Best submission |


## ğŸš€ How to Run

```bash
# 1. Activate environment
conda activate favorita-ts

# 2. Run CV tuning
python cv_run.py --config configs/config.yaml

# 3. Train final model
python train.py --config configs/config.yaml

# 4. Analyze errors
python analyze_errors.py --config configs/config.yaml
